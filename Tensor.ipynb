{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPya6M7EznOXZoM4g6L5wkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goldenkiwi-hyeuk/202112python/blob/main/Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "ccPGe_CtNN2x"
      },
      "outputs": [],
      "source": [
        "# 텐서플로 TensorFlow : 2015년 구글 브레인 팀에서 공개한 라이브러리\n",
        "# 파이썬 뿐만 아니라 JS Swift ...  등등 을 지원한다.\n",
        "# 텐서플로는 딥러닝 연산 처리 라이브러리\n",
        "# 이름에서 볼수 있듯 텐서 Tensor라고 불르는 데이터를 사용한다.\n",
        "# 노드와 노드를 연결하는 간선 edge로 이루어진 그래프 구조를  통해\n",
        "# 데이터를 이용시시키면서 연산이 이루어진다.\n",
        "\n",
        "# 텐서플로2의 특징\n",
        "# 1. 모델구조를 만들고 학습을 진행하는 과정이 직관적이다.\n",
        "# 2. 실행결과를 즉시 바로 확인 할수 있어 편리하다.\n",
        "# 3. 파이썬 도구를 사용해서 학습과정을 설계한다.\n",
        "# *. 텐서플로1은 일종의 컴파일러 방식으로 볼수 있고 텐서플로2느느 일종의 인터프리터 방식이라고 볼수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JZ3xm1fSQPmO"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1\n",
        "b = 2\n",
        "c= tf.math.add(a,b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59MZifG6RGh5",
        "outputId": "7454ce39-bfe2-4af8-b878-c2a97c3c1b11"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로의 자료구조\n",
        "# 텐서프로에서 자료를 표현하는 기본구조인 텐서\n",
        "\n",
        "# 0차원 텐서 - 스칼라 Scalar\n",
        "# 1차원 텐서 - 벡터 Vector\n",
        "# 2차원 텐서 - 행렬 Matrix\n",
        "# 고차원 텐서\n",
        "\n",
        "# 점이 선으로 선이 면으로 면이 입체로 변하는 공간개념으로 생각하자\n",
        "# 텐서에서의 각 차원은 각각 고유 정보를 나타내는 축이라고 이해하자\n",
        "\n",
        "# tensor의 사전적 의미 : '어떤 방향으로 뻗다', '어떤 방향으로 잡아당기다'\n",
        "# 즉 방향성을 갖는 어떤 물리량 -> 벡터\n",
        "\n",
        "# 스칼라 Scalar - 스칼라는 정수, 실수와 같은 상수를 나타낸다. 양은 나타내지만 방향성은 없다. 따라서 차수는 0이된다,\n",
        "#                 또 다른 표현으로 rank - 0 텐서(랭크제로텐서). 여기서 랭크는 텐서의 차수를 나타낸다."
      ],
      "metadata": {
        "id": "1rGD1mS_RRdR"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant(1)\n",
        "b = tf.constant(2)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "# shape =() 차수가 -인 스칼라를 의미한다.\n",
        "# 정수 1과 2는 0차원 텐서인 스칼라로 저장이 되었다.\n",
        "# dtype = int32   32비트 정수형"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jxzHE97TXRy",
        "outputId": "6b443b42-8f81-48bd-c05f-9824302b2b3c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.rank(a)) # 텐서플로의 데이터 타입을 자세히 확인 가능한 tf.rank()함수\n",
        "# 변수 a에 저장된 텐서의 랭크 값은 0인 스칼라 텐서"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OShGkwfRUCmF",
        "outputId": "f43108af-17da-4b84-da46-35638e0e36ef"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 자료변환\n",
        "a = tf.cast(a, tf.float32)"
      ],
      "metadata": {
        "id": "ImYD_CC1UfFX"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI8HDHpJU9Ty",
        "outputId": "ab0164b7-1530-449f-82de-6d6948ceabb0"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.cast(b, tf.float32)"
      ],
      "metadata": {
        "id": "VbLrc1rAU_6U"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHLWAPHYVU8Z",
        "outputId": "a21d8996-c761-49bb-bd53-fb9eff7400f5"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로에서는 float32를 숫자의 기본 자료형으로 사용한다."
      ],
      "metadata": {
        "id": "0EPXwPPHVZnE"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.math.add(a,b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78bdfr4sVRMk",
        "outputId": "f3ebdd15-e447-481e-c9b1-1747ca5aff19"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(c)\n",
        "# 의 결과는 <tf.Tensor: shape=(), dtype=int32, numpy=0>로 나온다.\n",
        "# 여기서 dtype =int32는 c의 차원이 0인데 차원의 데이터타입이 int32라는 의미이다.\n",
        "# c가 가지고 있는 값의 데이터 타입의 형태는 위의 결과처럼 float32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZoX8y0oVwD7",
        "outputId": "5949f483-b5ef-4412-c264-e4a4fbc73ba9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.subtract(a,b))\n",
        "# 빼기 subtract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvxliUW9V2MV",
        "outputId": "9b3e076b-2016-422b-8305-615e3ae5f437"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(-1.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.multiply(a,b))\n",
        "# 곱셉 multiply"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h7v6fimZGJi",
        "outputId": "b9bacdc4-a32b-4242-ec42-4f4c864bc13c"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.divide(a,b))\n",
        "# 나누기 divide"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wooSbvVmZYZ_",
        "outputId": "86e0dc4a-2123-4b91-9c4d-03cd30c00b45"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.5, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.mod(a,b))\n",
        "# 나머지 연산자 mod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y1p_hKtZpQk",
        "outputId": "153c3eb5-2fee-405f-d7c3-05071b1c58e4"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.floordiv(a,b))\n",
        "# 몫 연산자 floordiv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARN7-Z1TZvAe",
        "outputId": "990eff2e-4fb5-4904-987b-deb49af96d5c"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 (Vector) - 벡터는 여러개의 스칼라를 원소로 갖는 1차원의 배열\n",
        "#                 스칼라 여러개가 동일한 축 방향으로 나열되는 개념\n",
        "#                 벡터는 원소들로 구성되는 여러개의 값들을 모여서 하나의 대표성을 갖는 값이 된다.\n",
        "#                 각 원소들의 크기 뿐 아니라 원소들이 나열되는 순서에도 의미가 있다. 형태만 보면 파이썬의 리스트와 유사하다.\n",
        "#                 벡터는 하나의 축을 갖고 차수가 1인 랭크-1 텐서라고 부른다.\n",
        "\n",
        "py_list = [10,20,30]\n",
        "vec1 = tf.constant(py_list, dtype = tf.float32)\n",
        "print(vec1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgVeU-xWZ412",
        "outputId": "7a99559b-07d4-4267-803d-03c53f5ee556"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_arr = np.array([10.,10.,10.])\n",
        "vec2 = tf.constant(num_arr, dtype=tf.float32)\n",
        "\n",
        "print(vec2)\n",
        "# shape(3,) 원소의 갯수 1개의 축"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7t-baRrbYbv",
        "outputId": "f16a927f-c077-4266-d9c4-affe00976941"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.rank(vec1))\n",
        "print(tf.rank(vec2))\n",
        "# shape =()인 이유는 1차원이라는 것이 0차원으로 저장되었기 때문"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Tcfl9bb_Ny",
        "outputId": "2dbdcb68-37bc-43e8-f1a6-43ef1f7e336a"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add1 = tf.math.add(vec1,vec2)\n",
        "print(add1)\n",
        "print(tf.rank(add1))\n",
        "# 계산을 할때는 같은 위치에 있는 원소들끼리 짝을 이루어 계산한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DZcki5-ceqg",
        "outputId": "e0069f90-7966-42ad-c761-4afd8a4dc3c9"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add2 = vec1 + vec2\n",
        "print(add2)\n",
        "print(tf.rank(add2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbWWP7_hdLI7",
        "outputId": "6e81aaba-b932-4b12-be60-eb230eab8c05"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스칼라와 마찬가지로 벡터도 tf.math 모듈을통해 다양한 함수를 \n",
        "# 산술 연산을 할수 있따. 이때... 같은 위치에 있는 원소들끼리 연산한다.\n",
        "print(tf.math.subtract(vec1,vec2))\n",
        "print(tf.math.multiply(vec1,vec2))\n",
        "print(tf.math.divide(vec1,vec2))\n",
        "print(tf.math.mod(vec1,vec2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKSeUhvFdPxV",
        "outputId": "750f4bb4-4fbd-4192-efeb-25e099e30869"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([100. 200. 300.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec1-vec2)\n",
        "print(vec1*vec2)\n",
        "print(vec1/vec2)\n",
        "print(vec1%vec2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlqaHFz1eAv1",
        "outputId": "defd8d71-9fdb-4d5a-8c00-61803dd17a37"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([100. 200. 300.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 원소들의 합\n",
        "print(tf.reduce_sum(vec1))\n",
        "print(tf.reduce_sum(vec2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l18vUEhYeXZy",
        "outputId": "9583c600-8ccc-4d28-d907-2d4450227806"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(60.0, shape=(), dtype=float32)\n",
            "tf.Tensor(30.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 브로드 캐스팅 : 원소들 각 값에 계산하기\n",
        "print(vec1)\n",
        "print(vec1+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p0_ylNnejE6",
        "outputId": "3785b7d2-b69e-4a27-e318-16884ede140e"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([11. 21. 31.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행렬 Matrix\n",
        "# 행렬은 차수가1인 즉 벡터를 같은 축 방향으로 여러개를 나열하는 개념\n",
        "# 즉 1차원 벡터 여러개를 원호로 갖는 배열이다. 텐서플로에서는 랭크-2\n",
        "# pandas에서의 dataframe과 유사하다.\n",
        "\n",
        "# 2차원 리스트 생성\n",
        "list = [[10,20],[30,40]]\n",
        "\n",
        "# 텐서변환\n",
        "mat = tf.constant(list)\n",
        "print(mat)\n",
        "print(tf.rank(mat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXriQ_j3e3-5",
        "outputId": "a7006a7a-5a3c-453c-ce24-75db674e4e57"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10 20]\n",
            " [30 40]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec1 = tf.constant([1,0])\n",
        "vec2 = tf.constant([-1,2])\n",
        "\n",
        "# 텐서 변환\n",
        "mat2= tf.stack([vec1,vec2])\n",
        "print(mat2)\n",
        "print(tf.rank(mat2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDCCj9o1gGqw",
        "outputId": "9a68e9f7-0d20-4a61-eb85-c0ef5a8d368b"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  0]\n",
            " [-1  2]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 산술 연산\n",
        "mul = tf.math.multiply(mat, mat2)\n",
        "print(mul)\n",
        "print(tf.rank(mul))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WX-VLk8g_B5",
        "outputId": "2c39d89d-2078-41b5-b6e6-25192cfde756"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 10   0]\n",
            " [-30  80]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add = tf.math.add(mat,mat2)\n",
        "subtract = tf.math.subtract(mat,mat2)\n",
        "print(add)\n",
        "print(tf.rank(add))\n",
        "print(subtract)\n",
        "print(tf.rank(subtract))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_trkNiRhixO",
        "outputId": "dd7c03a9-9338-43f1-b06a-91f1b2d45859"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[11 20]\n",
            " [29 42]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 9 20]\n",
            " [31 38]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 매트릭스에서의 브로드 캐스팅\n",
        "bc = tf.math.multiply(mat,3)\n",
        "bc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of5XJnOliAWt",
        "outputId": "d73fa4c5-2684-45d2-b73c-3c0ece5b751f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 30,  60],\n",
              "       [ 90, 120]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add2 = mat + mat2\n",
        "add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX86wYHBiML5",
        "outputId": "9b6daed3-4ba2-4186-a586-65deef2a634a"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[11, 20],\n",
              "       [29, 42]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서를 넘파이로 변환\n",
        "\n",
        "np_arr = mat.numpy()\n",
        "np_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ppql_szik8t",
        "outputId": "74f910cb-630b-4d96-f707-5904252b8be0"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10, 20],\n",
              "       [30, 40]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(np_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFWPgJByizrX",
        "outputId": "0d6899a7-fccc-4b97-c7c1-942b6c60ae32"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 고차원 텐서는 너무 내용이 기니 패스"
      ],
      "metadata": {
        "id": "TtxrCuo1i5xC"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서에서의 인덱싱(indexing) - 위치를 기준으로 원소를 추출하는 방법\n",
        "# 파이썬 리스트 또는 넘파이 배열의 인덱싱과 유사하다.\n",
        "# 0부터 시작하고 마지막은 -1로 나타낸다.\n",
        "# 하나만 추출 뿐 아니라 여러 원소를 추출하는 슬라이싱(slicing)도 가능하다.\n",
        "\n",
        "vec = tf.constant([10,20,30,40,50])\n",
        "print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2bARrsRjVtQ",
        "outputId": "e59bfe7a-8b5a-4bfd-c9b3-4033284561d9"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30 40 50], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱싱방법이 리스트와 동일\n",
        "vec[0] # 프린트를 생략하면 모양이 이상하게 나오기 때문에 print함수를 넣어서 확인하자\n",
        "print(vec[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LOLcT5WnwDv",
        "outputId": "8373a7e2-bc6e-49bc-b57b-bfaecc8103a1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4FycnMoIz0",
        "outputId": "ee64b8c8-7b28-417c-e4e4-5a9c95500b48"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(50, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec[:3])\n",
        "# 여러개의 원소를 슬라이싱하니 벡터로 나옴"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgXr_zrJoNgI",
        "outputId": "121dce9c-75b4-4767-fdd1-ac0d5957ce6b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = tf.constant([[10,20,30],[40,50,60]])\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXV8aDvqoWrW",
        "outputId": "c2fb865e-6c9c-4ac2-d29c-6ed416052922"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10 20 30]\n",
            " [40 50 60]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix의 슬라이싱\n",
        "print(mat[0,:]) # 0번째 행의 모든 열"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMOB1i2boxIY",
        "outputId": "81667696-69c9-46f8-f249-710777cfcf67"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat[:,1]) # 모든 행의 1열 값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n34goda8o3EH",
        "outputId": "af566c37-bf3e-4b5c-9f95-7dfd53fff550"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20 50], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 형태 변환 reshape\n",
        "# 앞으로의 머신러닝, 딥러닝에서 텐서 형태를 변환하는 것은 매우 중요하다.\n",
        "\n",
        "tensor = tf.constant(range(0,24))\n",
        "tensor # 1열로 나열된 1차원 데이터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knSsMs7xpFdL",
        "outputId": "30234f2a-9f54-43f3-a257-9003de89807d"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (24,) -> (3,8)\n",
        "tensor1 = tf.reshape(tensor, [3,8])\n",
        "print(tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY-aPaVRqMGq",
        "outputId": "b74e88ce-b179-4195-c428-4cdd887ad96f"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7]\n",
            " [ 8  9 10 11 12 13 14 15]\n",
            " [16 17 18 19 20 21 22 23]], shape=(3, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -1을 지정하면 '어떤 값이 와도 상관없다.'\n",
        "# (3,8) -> (4,)\n",
        "tensor2 = tf.reshape(tensor1, [-1,4])\n",
        "print(tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxXzAsiWqnlT",
        "outputId": "4deb1201-9271-4096-b020-a5a2416e933c"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]\n",
            " [16 17 18 19]\n",
            " [20 21 22 23]], shape=(6, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배열을 구성하는 원소가 매우 많고 배열 구조를 알지 못할때\n",
        "tensor3 = tf.reshape(tensor2, [-1]) # 뒤에 아무값도 없이 -1을 넣으면 1차원이 되버림\n",
        "print(tensor3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IIwILgurCkm",
        "outputId": "bca0808f-b7ae-46a1-be67-2a38530183e2"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다차원 텐서\n",
        "tensor4 = tf.reshape(tensor3, [-1,3,4])\n",
        "print(tensor4) # 고차원 (3,4)짜리 행렬이 2개가 되는 다차원 텐서가 되버림"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6XHTEQ2rp-o",
        "outputId": "badc3bc0-14fb-4f54-a038-f4c77231ef22"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]\n",
            "  [ 8  9 10 11]]\n",
            "\n",
            " [[12 13 14 15]\n",
            "  [16 17 18 19]\n",
            "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor5 = tf.reshape(tensor4, [3,2,4]) # 행이 2개 열이 4개인 행렬이 3개인 다차원 형태\n",
        "print(tensor5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHVbTEiur0N8",
        "outputId": "d04369ee-aa8b-46ca-f92c-2396b6f787aa"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]]\n",
            "\n",
            " [[ 8  9 10 11]\n",
            "  [12 13 14 15]]\n",
            "\n",
            " [[16 17 18 19]\n",
            "  [20 21 22 23]]], shape=(3, 2, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor6 = tf.reshape(tensor5, [3,2,2,2])\n",
        "print(tensor6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e1BYFiJsLru",
        "outputId": "6c1cde37-5cb2-459c-b4aa-f2c13596c6b0"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[ 0  1]\n",
            "   [ 2  3]]\n",
            "\n",
            "  [[ 4  5]\n",
            "   [ 6  7]]]\n",
            "\n",
            "\n",
            " [[[ 8  9]\n",
            "   [10 11]]\n",
            "\n",
            "  [[12 13]\n",
            "   [14 15]]]\n",
            "\n",
            "\n",
            " [[[16 17]\n",
            "   [18 19]]\n",
            "\n",
            "  [[20 21]\n",
            "   [22 23]]]], shape=(3, 2, 2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.Variable 변수\n",
        "\n",
        "# 텐서 플로는 그래프 구조를 이용하여 복잡한 미분 연산을 한다. 이떄 수많은 미분연산을 반복하게 된다.\n",
        "# 이때 각각의 중간 연산 결과를 저장하는 용도로도 변수를 이용하게 된다. 모델을 학습하는 중간 단꼐마다 모델의 가중치를\n",
        "# 변수에 저장하고 계속 반복하면서 변수 값을 업데이트한다.\n",
        "\n",
        "tensor1 = tf.constant([[0,2,3],[3,4,5]])\n",
        "print(tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPCc2szdsZnK",
        "outputId": "bd17277a-c151-4785-d71a-80eabb0a9442"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 2 3]\n",
            " [3 4 5]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1 = tf.Variable(tensor1)\n",
        "print(tensor_var1)\n",
        "\n",
        "# 변수는 텐서 구조에 저장되어있는 값이 달라질 수 있다는 점에서 값을 변경 할수 없는 상수 형태의 텐서를 만드는 constant함수와 구별된다.\n",
        "# 상수와 변수의 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kV4d4eptRYp",
        "outputId": "cfeca5e8-5862-4a18-c77c-4e2a1a56ac36"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[0, 2, 3],\n",
            "       [3, 4, 5]], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CgWFHho_tdCe",
        "outputId": "56e7ffb1-8aaa-43a8-fcb6-a3281eb1f41e"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Variable:0'"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZH0KkCTt5Oj",
        "outputId": "0cf9ab8e-9afc-455b-f143-996876d15195"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnrV4dzduC91",
        "outputId": "9a12143d-8b3f-4b93-cdb4-0f29a0d6277d"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.int32"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.numpy()\n",
        "\n",
        "# 변수로 설정하면 변수의 이름 크기 자료형 배열을 확인할수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2y3ruSeuElT",
        "outputId": "7d65bc7b-7462-4401-e4de-0048bc33ed56"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2, 3],\n",
              "       [3, 4, 5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assing() 매소드를 이용하여 변수에 새로운 데이터를 할당 할수도 있다.\n",
        "\n",
        "tensor_var1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4NVCa3AuGoE",
        "outputId": "76585de9-9017-472a-8961-2a799eee5d89"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [2, 2, 2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.assign([[1,1,1],[2,2,2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPF1na9IubxK",
        "outputId": "f43dc611-084a-457c-ddd8-05d534c50239"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [2, 2, 2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert_to_tensor() 함수를 사용하면 변수를 텐서로 변환할수 잇따.\n",
        "# 텐서로 변환하고 나면 그 텐서의 크기와 값을 변경할수 없다."
      ],
      "metadata": {
        "id": "C__xkNqBulpa"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2 = tf.convert_to_tensor(tensor_var1)\n",
        "print(tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-OOcW4YvVEn",
        "outputId": "9f9dee46-4b34-43f5-9429-08c6ae19ca9b"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 1 1]\n",
            " [2 2 2]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특히 텐서 변수는 name 속성을 갖을 수 있다.\n",
        "tensor_var2 = tf.Variable(tensor2, name = \"New Name\")\n",
        "print(tensor_var1)\n",
        "print(tensor_var2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PpsdLaEvjtU",
        "outputId": "e7ea6308-1b11-45f3-8dff-28235b9a33c5"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[1, 1, 1],\n",
            "       [2, 2, 2]], dtype=int32)>\n",
            "<tf.Variable 'New Name:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[1, 1, 1],\n",
            "       [2, 2, 2]], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 변수도 텐서 연산과 동일하게 사칙연산등의 계산을 처리할 수 있다.\n",
        "tensor_var1 + tensor_var2\n",
        "# 계산의 결과이기 때문에 tf.Tensor로 출력되는 것임 만약 변수로 할당하고 해당 변수를 출력하면 tf.Variable로 나옴"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ephECeCiv8dy",
        "outputId": "62e94736-5fd0-4f81-b920-9f0710e25374"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[2, 2, 2],\n",
              "       [4, 4, 4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자동 미분 automatic differentiation\n",
        "\n",
        "# 텐섭플로는 딥러닝 모델을 구성하는 복잡한 인공 신경만의 각 노드에서 계산되는 미분을 자동으로 계산해 준다.\n",
        "# 특히 가 변수의 기울기에 해당하는 그래디언트를 계싼하는데 특화되어 있다.\n",
        "\n",
        "# y = 3x-2 함수식에서 기울기와 y 절편 값을 텐서 자동 미분을 통해 계산\n",
        "\n",
        "# y = 3x-2\n",
        "g = tf.random.Generator.from_seed(2020)\n",
        "X= g.normal(shape=(10,))\n",
        "Y= 3*X-2\n",
        "print(X.numpy())\n",
        "print(Y.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134H3RV0wSWg",
        "outputId": "fc889b06-3bc7-405c-a897-e21bc7dfe474"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
            "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
            "[-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
            "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras.io\n",
        "# Keras : 딥러닝 라이브러리들을 쉽고 간결하게 사용할 수 있도록 하는 것이 목적\n",
        "# 케라스 2.3까지는 다른 딥러닝 라이브러리 들도 지원했지만\n",
        "# 2.4부터는 더이상 다른 라이브러리를 지원하지 않고 오직 텐서플로만 지원한다.\n",
        "\n",
        "# 하이퍼파라미터 hyper parameter - 파이썬에서의 하이퍼파라미터와는 다른 의미를 갖는다.\n",
        "#                                  일반적인 하이퍼 파라미터는 딥러닝 뿐 아니라 머신러닝 모델을 훈련할떄 사용자가 직접 설정해주는 설정 값을 뜻한다.\n",
        "#                                  가중치(weights) 편향(bias)는 자동으로 업데이트 되지만 학습 속도나 반복 훈련횟수 등 사용자가 직접 설정해야 하는 값들이 많다.\n",
        "#                                  사용자가 어떤 값을 설정하느냐에 따라 모델 성은과 결과가 달라진다.\n",
        "\n",
        "# 과소 적합 underfitting vs 과대적합 overfitting\n",
        "\n",
        "# 에포크 (epoch) - 딥러닝은 데이터셋을 학습하는 과정을 엄청나게 많이 반복하면서 최적의 모델 가중치를 찾는 과정이다\n",
        "#                  반복 훈련을 할떄 데이터 셋을 전부 학습에 사용하는 1회의 훈련 루프를 1 epoch\n",
        "#                  특히 에폭은 중요한 파라미터이다. 과소적합이다라고 판단되면 epoch을 늘려서 다시 학습시킬 필요가 있다.\n",
        "#                  과대적합이다라고 판단되면 epoch를 줄여서 학습을 조기 종료시키는 것이 과대 적합을 방지하는 하나의 방법이다.\n",
        "\n",
        "# 손실 함수 loss fuction 예측 값과 정답 간의 차이 또는 오차(출력값과 실제값의 차이)"
      ],
      "metadata": {
        "id": "t8a9_GVZxkMt"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_linear(w=0.5, b=0.8, size = 50, noise=1.0):\n",
        "  x = np.random.rand(size)\n",
        "  y = w*x+b\n",
        "  noise = np.random.uniform(-abs(noise), abs(noise), size = y.shape)\n",
        "  yy =y + noise\n",
        "  plt.figure(figsize = (10,7))\n",
        "  plt.plot(x,y,color='r', label=f'y={w}*x+{b}')\n",
        "  plt.scatter(x,yy, label = 'data')\n",
        "  plt.legend(fontsize = 20)\n",
        "  plt.show()\n",
        "  print(f'w:{w}, b{b}')\n",
        "  return x, yy\n",
        "\n",
        "x,y =make_linear(w = 0.3, b =0.5 , size = 100, noise = 0.01)\n",
        "# 생성된 y 데이터는 y = 0.3x+0.5식과 완전히 일치하지 않고\n",
        "# 약간의 노이즈가 추가되었다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "TU6FwPHw4eoM",
        "outputId": "70d2aa51-9500-4c67-c910-11e210666a39"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:0.3, b0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 프로세스\n",
        "\n",
        "# 데이터 로드 -> 데이터 전처리(결측치 이상치 처리) -> 데이터분할(훈련용,검증용) -> 모델 생성 -> 훈련 -> 검증 -> 예측"
      ],
      "metadata": {
        "id": "BtMRlP5l5rXu"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as pd\n",
        "\n",
        "x = np.arange(1,6)\n",
        "y = 3*x+2\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEp2vtFa7S4E",
        "outputId": "240f4598-cee2-43cd-8bce-99da1eca2616"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "[ 5  8 11 14 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "z34QAMS77g60",
        "outputId": "a4a2cd04-38a2-4557-992a-0e616213ce33"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3d95f27cd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 194
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서프로 케라스는 보통 세 가지 방식으로 모델을 생성한다.\n",
        "# 그 중 제일 간결한 Sequential API 방식을 사용하면 쉽게 만들 수 있다.\n",
        "# 층을 이어 붙이듯 일렬로 연결하는 방식이다. 따라서 입력 레이어 부터\n",
        "# 출력 레이어까지 순서를 갖는다.\n",
        "# 입력 데이터는 시퀀스에 가장 앞에 위치하고 순서대로 각 층을 하나씩 통과 하면서 딥러닝 연산을 수행하게 된다.\n",
        "\n",
        "# 직관적으로 구조를 이해랄 수 있기 때문에 케라스 중 가장 간단한 방법이다.\n",
        "# 2개 이상의 다중 입력이나 다중 출력을 갖는 복잡한 구조를 만들수는 없다.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10),\n",
        "        tf.keras.layers.Dense(5),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "mgeBeWoz7tiu"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add 함수를 통해서 추가로 층을 추가할 수 있다.\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(5))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "IVTzbi2-8I6n"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential API를 사용하여 모델을 구성할 때는 반드시 첫번째 층은\n",
        "# input_shape 매개변수를 지정해야 한다. input_shape 매개변수는 주입할 데이터셋의\n",
        "# shape을 튜플 혹은 리스트로 지정할 수 있다.\n",
        "# 예를들면 데이터셋의 shape이 (150,4)로 구성되었다고 가정하면\n",
        "# input_shape은 (4,) 혹은 [4]로 지정한다.\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[4]),\n",
        "  tf.keras.layers.Dense(5),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n"
      ],
      "metadata": {
        "id": "fGlusx12-Fgw"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순선형회귀 모델\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])"
      ],
      "metadata": {
        "id": "SrfeKiR7-c4j"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# 모델의 요약 : 구조를 확인할 수 있고 층별 노드의 개수가 표기된다.\n",
        "#               하단에는 훈련시 업데이트 할 파라미터의 개수가 표시된다.\n",
        "\n",
        "# Total params 모델 내부에 존재하는 모든 파라미터의 합계\n",
        "# Trainable params 모델 훈련 시 업데이트 할 파라미터의 총 개수\n",
        "# Non-trainable params 모델 훈련 시 업데이트 하지 않을 파라미터의 총 개수\n",
        "\n",
        "# 단순선형회귀 모델에서는 업데이트 파라미터가 가중치 w 편향  b 2개이다\n",
        "# 따라서 총 Param의 개수가 2개로 표기되는 것을 확인 할 수 있다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPElU7OnCXj1",
        "outputId": "0f800730-f050-4ea9-c7ff-2a5e6e747437"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer ='sgd', loss = 'mse', metrics= ['mse', 'mae'])\n",
        "# sgd 경사하강법 - 최적화 방법\n",
        "# 평가 지표와 손실 함수 :  mse 평균 제곱 오차 mae 평균 절대 오차"
      ],
      "metadata": {
        "id": "kQtQjhxbDq2e"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x,y,epochs= 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp7Uhf5-FPWX",
        "outputId": "f24167de-4b30-4d1c-8cca-ac395b572a02"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 96.2812 - mse: 96.2812 - mae: 9.2056\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.2227 - mse: 56.2227 - mae: 7.0763\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 32.8779 - mse: 32.8779 - mae: 5.4506\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.2729 - mse: 19.2729 - mae: 4.2094\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3438 - mse: 11.3438 - mae: 3.2618\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7223 - mse: 6.7223 - mae: 2.5382\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0284 - mse: 4.0284 - mae: 1.9857\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4578 - mse: 2.4578 - mae: 1.5637\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5418 - mse: 1.5418 - mae: 1.2414\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0072 - mse: 1.0072 - mae: 0.9953\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6950 - mse: 0.6950 - mae: 0.8072\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5123 - mse: 0.5123 - mae: 0.6634\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4051 - mse: 0.4051 - mae: 0.5535\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3419 - mse: 0.3419 - mae: 0.4789\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3044 - mse: 0.3044 - mae: 0.4549\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2818 - mse: 0.2818 - mae: 0.4364\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2680 - mse: 0.2680 - mae: 0.4219\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2592 - mse: 0.2592 - mae: 0.4134\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.4155\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - mse: 0.2493 - mae: 0.4168\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2462 - mse: 0.2462 - mae: 0.4175\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2438 - mse: 0.2438 - mae: 0.4176\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2416 - mse: 0.2416 - mae: 0.4174\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2397 - mse: 0.2397 - mae: 0.4169\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2380 - mse: 0.2380 - mae: 0.4162\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - mae: 0.4153\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2346 - mse: 0.2346 - mae: 0.4143\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2330 - mse: 0.2330 - mae: 0.4132\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2314 - mse: 0.2314 - mae: 0.4121\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2298 - mse: 0.2298 - mae: 0.4109\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2283 - mse: 0.2283 - mae: 0.4096\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2267 - mse: 0.2267 - mae: 0.4083\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2252 - mse: 0.2252 - mae: 0.4070\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2237 - mse: 0.2237 - mae: 0.4057\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2222 - mse: 0.2222 - mae: 0.4044\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2207 - mse: 0.2207 - mae: 0.4031\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2192 - mse: 0.2192 - mae: 0.4017\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2177 - mse: 0.2177 - mae: 0.4004\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2162 - mse: 0.2162 - mae: 0.3991\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2148 - mse: 0.2148 - mae: 0.3977\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2133 - mse: 0.2133 - mae: 0.3964\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2119 - mse: 0.2119 - mae: 0.3951\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2104 - mse: 0.2104 - mae: 0.3937\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2090 - mse: 0.2090 - mae: 0.3924\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2076 - mse: 0.2076 - mae: 0.3911\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2062 - mse: 0.2062 - mae: 0.3898\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2048 - mse: 0.2048 - mae: 0.3884\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2034 - mse: 0.2034 - mae: 0.3871\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2021 - mse: 0.2021 - mae: 0.3858\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2007 - mse: 0.2007 - mae: 0.3845\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1993 - mse: 0.1993 - mae: 0.3832\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1980 - mse: 0.1980 - mae: 0.3819\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1967 - mse: 0.1967 - mae: 0.3806\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1953 - mse: 0.1953 - mae: 0.3794\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1940 - mse: 0.1940 - mae: 0.3781\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1927 - mse: 0.1927 - mae: 0.3768\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1914 - mse: 0.1914 - mae: 0.3755\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1901 - mse: 0.1901 - mae: 0.3742\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1888 - mse: 0.1888 - mae: 0.3730\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1876 - mse: 0.1876 - mae: 0.3717\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1863 - mse: 0.1863 - mae: 0.3705\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1850 - mse: 0.1850 - mae: 0.3692\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1838 - mse: 0.1838 - mae: 0.3680\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1825 - mse: 0.1825 - mae: 0.3667\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1813 - mse: 0.1813 - mae: 0.3655\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1801 - mse: 0.1801 - mae: 0.3642\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1789 - mse: 0.1789 - mae: 0.3630\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1777 - mse: 0.1777 - mae: 0.3618\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1765 - mse: 0.1765 - mae: 0.3606\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1753 - mse: 0.1753 - mae: 0.3593\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1741 - mse: 0.1741 - mae: 0.3581\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1729 - mse: 0.1729 - mae: 0.3569\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1717 - mse: 0.1717 - mae: 0.3557\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1706 - mse: 0.1706 - mae: 0.3545\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1694 - mse: 0.1694 - mae: 0.3533\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1683 - mse: 0.1683 - mae: 0.3521\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1672 - mse: 0.1672 - mae: 0.3509\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1660 - mse: 0.1660 - mae: 0.3497\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1649 - mse: 0.1649 - mae: 0.3486\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1638 - mse: 0.1638 - mae: 0.3474\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1627 - mse: 0.1627 - mae: 0.3462\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1616 - mse: 0.1616 - mae: 0.3450\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1605 - mse: 0.1605 - mae: 0.3439\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1594 - mse: 0.1594 - mae: 0.3427\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1583 - mse: 0.1583 - mae: 0.3415\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1573 - mse: 0.1573 - mae: 0.3404\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1562 - mse: 0.1562 - mae: 0.3392\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1552 - mse: 0.1552 - mae: 0.3381\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1541 - mse: 0.1541 - mae: 0.3369\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1531 - mse: 0.1531 - mae: 0.3358\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1520 - mse: 0.1520 - mae: 0.3347\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1510 - mse: 0.1510 - mae: 0.3335\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1500 - mse: 0.1500 - mae: 0.3324\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1490 - mse: 0.1490 - mae: 0.3313\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1480 - mse: 0.1480 - mae: 0.3302\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1470 - mse: 0.1470 - mae: 0.3291\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1460 - mse: 0.1460 - mae: 0.3279\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1450 - mse: 0.1450 - mae: 0.3268\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1440 - mse: 0.1440 - mae: 0.3257\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1430 - mse: 0.1430 - mae: 0.3246\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1421 - mse: 0.1421 - mae: 0.3235\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1411 - mse: 0.1411 - mae: 0.3224\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1402 - mse: 0.1402 - mae: 0.3213\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1392 - mse: 0.1392 - mae: 0.3203\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1383 - mse: 0.1383 - mae: 0.3192\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1373 - mse: 0.1373 - mae: 0.3181\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1364 - mse: 0.1364 - mae: 0.3170\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1355 - mse: 0.1355 - mae: 0.3159\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1346 - mse: 0.1346 - mae: 0.3149\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1337 - mse: 0.1337 - mae: 0.3138\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1328 - mse: 0.1328 - mae: 0.3128\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1319 - mse: 0.1319 - mae: 0.3117\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1310 - mse: 0.1310 - mae: 0.3106\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1301 - mse: 0.1301 - mae: 0.3096\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1292 - mse: 0.1292 - mae: 0.3085\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1284 - mse: 0.1284 - mae: 0.3075\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1275 - mse: 0.1275 - mae: 0.3065\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1266 - mse: 0.1266 - mae: 0.3054\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1258 - mse: 0.1258 - mae: 0.3044\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1249 - mse: 0.1249 - mae: 0.3034\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1241 - mse: 0.1241 - mae: 0.3023\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1232 - mse: 0.1232 - mae: 0.3013\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1224 - mse: 0.1224 - mae: 0.3003\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1216 - mse: 0.1216 - mae: 0.2993\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1208 - mse: 0.1208 - mae: 0.2983\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1199 - mse: 0.1199 - mae: 0.2973\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1191 - mse: 0.1191 - mae: 0.2963\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1183 - mse: 0.1183 - mae: 0.2953\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1175 - mse: 0.1175 - mae: 0.2943\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1167 - mse: 0.1167 - mae: 0.2933\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1160 - mse: 0.1160 - mae: 0.2923\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1152 - mse: 0.1152 - mae: 0.2913\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1144 - mse: 0.1144 - mae: 0.2903\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1136 - mse: 0.1136 - mae: 0.2893\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1129 - mse: 0.1129 - mae: 0.2883\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1121 - mse: 0.1121 - mae: 0.2874\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1113 - mse: 0.1113 - mae: 0.2864\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1106 - mse: 0.1106 - mae: 0.2854\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1098 - mse: 0.1098 - mae: 0.2845\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1091 - mse: 0.1091 - mae: 0.2835\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1084 - mse: 0.1084 - mae: 0.2825\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1076 - mse: 0.1076 - mae: 0.2816\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.1069 - mae: 0.2806\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2797\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2787\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1047 - mse: 0.1047 - mae: 0.2778\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1040 - mse: 0.1040 - mae: 0.2769\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2759\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1026 - mse: 0.1026 - mae: 0.2750\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2741\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1013 - mse: 0.1013 - mae: 0.2731\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1006 - mse: 0.1006 - mae: 0.2722\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0999 - mse: 0.0999 - mae: 0.2713\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2704\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0986 - mse: 0.0986 - mae: 0.2695\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0979 - mse: 0.0979 - mae: 0.2685\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0972 - mse: 0.0972 - mae: 0.2676\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2667\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2658\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2649\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0946 - mse: 0.0946 - mae: 0.2640\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0940 - mse: 0.0940 - mae: 0.2631\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0934 - mse: 0.0934 - mae: 0.2623\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2614\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0921 - mse: 0.0921 - mae: 0.2605\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0915 - mse: 0.0915 - mae: 0.2596\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0909 - mse: 0.0909 - mae: 0.2587\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0902 - mse: 0.0902 - mae: 0.2579\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0896 - mse: 0.0896 - mae: 0.2570\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0890 - mse: 0.0890 - mae: 0.2561\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0884 - mse: 0.0884 - mae: 0.2552\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2544\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2535\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0867 - mse: 0.0867 - mae: 0.2527\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0861 - mse: 0.0861 - mae: 0.2518\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0855 - mse: 0.0855 - mae: 0.2510\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0849 - mse: 0.0849 - mae: 0.2501\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0843 - mse: 0.0843 - mae: 0.2493\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0838 - mse: 0.0838 - mae: 0.2484\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0832 - mse: 0.0832 - mae: 0.2476\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0826 - mse: 0.0826 - mae: 0.2467\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0821 - mse: 0.0821 - mae: 0.2459\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0815 - mse: 0.0815 - mae: 0.2451\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0810 - mse: 0.0810 - mae: 0.2442\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0804 - mse: 0.0804 - mae: 0.2434\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0799 - mse: 0.0799 - mae: 0.2426\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0793 - mse: 0.0793 - mae: 0.2418\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0788 - mse: 0.0788 - mae: 0.2410\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0783 - mse: 0.0783 - mae: 0.2401\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0778 - mse: 0.0778 - mae: 0.2393\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0772 - mse: 0.0772 - mae: 0.2385\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0767 - mse: 0.0767 - mae: 0.2377\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0762 - mse: 0.0762 - mae: 0.2369\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2361\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0752 - mse: 0.0752 - mae: 0.2353\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0747 - mse: 0.0747 - mae: 0.2345\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0742 - mse: 0.0742 - mae: 0.2337\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0737 - mse: 0.0737 - mae: 0.2329\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0732 - mse: 0.0732 - mae: 0.2322\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0727 - mse: 0.0727 - mae: 0.2314\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0722 - mse: 0.0722 - mae: 0.2306\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0717 - mse: 0.0717 - mae: 0.2298\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0712 - mse: 0.0712 - mae: 0.2290\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0707 - mse: 0.0707 - mae: 0.2283\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0702 - mse: 0.0702 - mae: 0.2275\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0698 - mse: 0.0698 - mae: 0.2267\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0693 - mse: 0.0693 - mae: 0.2259\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0688 - mse: 0.0688 - mae: 0.2252\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0684 - mse: 0.0684 - mae: 0.2244\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0679 - mse: 0.0679 - mae: 0.2237\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0674 - mse: 0.0674 - mae: 0.2229\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0670 - mse: 0.0670 - mae: 0.2222\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0665 - mse: 0.0665 - mae: 0.2214\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0661 - mse: 0.0661 - mae: 0.2207\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.2199\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0652 - mse: 0.0652 - mae: 0.2192\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0648 - mse: 0.0648 - mae: 0.2184\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0643 - mse: 0.0643 - mae: 0.2177\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0639 - mse: 0.0639 - mae: 0.2169\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0635 - mse: 0.0635 - mae: 0.2162\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0630 - mse: 0.0630 - mae: 0.2155\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0626 - mse: 0.0626 - mae: 0.2148\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0622 - mse: 0.0622 - mae: 0.2140\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0618 - mse: 0.0618 - mae: 0.2133\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.2126\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0609 - mse: 0.0609 - mae: 0.2119\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.2111\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2104\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0597 - mse: 0.0597 - mae: 0.2097\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0593 - mse: 0.0593 - mae: 0.2090\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.2083\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0585 - mse: 0.0585 - mae: 0.2076\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0581 - mse: 0.0581 - mae: 0.2069\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.2062\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0573 - mse: 0.0573 - mae: 0.2055\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.2048\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.2041\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.2034\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.2027\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.2021\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.2014\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.2007\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.2000\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1993\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.1987\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1980\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.1973\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1967\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1960\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.1953\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1947\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1940\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1934\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1927\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1920\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1914\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1907\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1901\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1895\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1888\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1882\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1875\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1869\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1863\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1857\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1850\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1844\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1838\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1832\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1825\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1819\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1813\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1807\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1801\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1795\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0434 - mse: 0.0434 - mae: 0.1789\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1783\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0428 - mse: 0.0428 - mae: 0.1777\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1771\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0423 - mse: 0.0423 - mae: 0.1765\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1759\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1753\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1747\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1741\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1735\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1729\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1723\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1717\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1712\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1706\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1700\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1694\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0387 - mse: 0.0387 - mae: 0.1689\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0384 - mse: 0.0384 - mae: 0.1683\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1677\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1671\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1666\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0374 - mse: 0.0374 - mae: 0.1660\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1655\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1649\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1643\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0364 - mse: 0.0364 - mae: 0.1638\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0362 - mse: 0.0362 - mae: 0.1632\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0359 - mse: 0.0359 - mae: 0.1627\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1621\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1616\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1610\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0350 - mse: 0.0350 - mae: 0.1605\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0347 - mse: 0.0347 - mae: 0.1599\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0345 - mse: 0.0345 - mae: 0.1594\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.1589\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0340 - mse: 0.0340 - mae: 0.1583\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1578\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.1573\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0333 - mse: 0.0333 - mae: 0.1567\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0331 - mse: 0.0331 - mae: 0.1562\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.1557\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.1551\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.1546\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1541\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.1536\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0318 - mse: 0.0318 - mae: 0.1531\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1525\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0314 - mse: 0.0314 - mae: 0.1520\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0312 - mse: 0.0312 - mae: 0.1515\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0309 - mse: 0.0309 - mae: 0.1510\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0307 - mse: 0.0307 - mae: 0.1505\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0305 - mse: 0.0305 - mae: 0.1500\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0303 - mse: 0.0303 - mae: 0.1495\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0301 - mse: 0.0301 - mae: 0.1490\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0299 - mse: 0.0299 - mae: 0.1485\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.1480\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0295 - mse: 0.0295 - mae: 0.1475\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0293 - mse: 0.0293 - mae: 0.1470\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0291 - mse: 0.0291 - mae: 0.1465\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1460\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - mae: 0.1455\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0285 - mse: 0.0285 - mae: 0.1450\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0283 - mse: 0.0283 - mae: 0.1445\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0281 - mse: 0.0281 - mae: 0.1440\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0280 - mse: 0.0280 - mae: 0.1435\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0278 - mse: 0.0278 - mae: 0.1430\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0276 - mse: 0.0276 - mae: 0.1426\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0274 - mse: 0.0274 - mae: 0.1421\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - mae: 0.1416\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0270 - mse: 0.0270 - mae: 0.1411\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - mae: 0.1406\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0267 - mse: 0.0267 - mae: 0.1402\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0265 - mse: 0.0265 - mae: 0.1397\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0263 - mse: 0.0263 - mae: 0.1392\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0261 - mse: 0.0261 - mae: 0.1387\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0260 - mse: 0.0260 - mae: 0.1383\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - mae: 0.1378\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - mae: 0.1373\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0254 - mse: 0.0254 - mae: 0.1369\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - mae: 0.1364\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - mae: 0.1360\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0249 - mse: 0.0249 - mae: 0.1355\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - mae: 0.1350\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - mae: 0.1346\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1341\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0243 - mse: 0.0243 - mae: 0.1337\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1332\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0239 - mse: 0.0239 - mae: 0.1328\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0238 - mse: 0.0238 - mae: 0.1323\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0236 - mse: 0.0236 - mae: 0.1319\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1314\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1310\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1305\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0230 - mse: 0.0230 - mae: 0.1301\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0228 - mse: 0.0228 - mae: 0.1297\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0227 - mse: 0.0227 - mae: 0.1292\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1288\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1283\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1279\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1275\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1270\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1266\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1262\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0215 - mse: 0.0215 - mae: 0.1258\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213 - mae: 0.1253\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.1249\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1245\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0209 - mse: 0.0209 - mae: 0.1241\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0208 - mse: 0.0208 - mae: 0.1237\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0206 - mse: 0.0206 - mae: 0.1232\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0205 - mse: 0.0205 - mae: 0.1228\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1224\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1220\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1216\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.1212\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0198 - mse: 0.0198 - mae: 0.1208\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.1203\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0195 - mse: 0.0195 - mae: 0.1199\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1195\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.1191\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.1187\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.1183\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1179\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0187 - mse: 0.0187 - mae: 0.1175\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.1171\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.1167\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.1163\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.1159\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0181 - mse: 0.0181 - mae: 0.1156\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.1152\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.1148\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.1144\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.1140\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.1136\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.1132\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.1128\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.1125\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.1121\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.1117\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.1113\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.1110\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.1106\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.1102\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.1098\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.1095\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.1091\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.1087\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0159 - mse: 0.0159 - mae: 0.1084\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.1080\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.1076\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.1073\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.1069\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.1065\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.1062\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.1058\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.1055\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.1051\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.1047\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.1044\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.1040\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.1037\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.1033\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.1030\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.1026\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.1023\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.1019\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.1016\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.1013\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.1009\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.1006\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.1002\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0999\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0996\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0992\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0989\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0985\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0982\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0979\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0976\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0972\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0969\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0966\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0962\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0959\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0956\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0953\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0949\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0946\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0943\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0940\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0937\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0934\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0930\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0927\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0924\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0921\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0918\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0915\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0912\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0909\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0905\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0902\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0899\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0896\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0893\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0890\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0887\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0884\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0881\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0878\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0875\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0872\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0869\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0866\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0864\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0861\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0858\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0855\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0852\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0849\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0846\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0843\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0840\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0838\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0835\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0832\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0829\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0826\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0824\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0821\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0818\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0815\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0812\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0810\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0807\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0804\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0802\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0799\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0796\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0793\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0791\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0788\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0785\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0783\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0780\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0777\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0775\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0772\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0770\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0767\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0764\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0762\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0759\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0757\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0754\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0752\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0749\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0747\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0744\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0741\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0739\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0736\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0734\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0732\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0729\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0727\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0724\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0722\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0719\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0717\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0714\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0712\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0710\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0707\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0705\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0702\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0700\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0698\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0695\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0693\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0691\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0688\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0686\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0684\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0681\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0679\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0677\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0674\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0672\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0670\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0668\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0665\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0663\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0661\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0659\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0656\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0654\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0652\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0650\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0648\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0645\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0643\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0641\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0639\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0637\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0635\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0632\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0630\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0628\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0626\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0624\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0622\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0620\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0618\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0615\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0613\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0611\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0609\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0607\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0605\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0603\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0601\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0599\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0597\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0595\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0593\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0591\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0589\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0587\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0585\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0583\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0581\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0579\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0577\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0575\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0573\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0571\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0569\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0567\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0566\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0564\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0562\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0560\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0558\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0556\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0554\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0552\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0550\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0549\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0547\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0545\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0543\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0541\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0539\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0537\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0536\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0534\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0532\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0530\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0528\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0527\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0525\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0523\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0521\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0520\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0518\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0516\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0514\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0513\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0511\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0509\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0507\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0506\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0504\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0502\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0501\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0499\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0497\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0496\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0494\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0492\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0491\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0489\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0487\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0486\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0484\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0482\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0481\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0479\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0477\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0476\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0474\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0473\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0471\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0469\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0468\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0466\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0465\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0463\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0462\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0460\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0458\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0457\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0455\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0454\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0452\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0451\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0449\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0448\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0446\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0445\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0443\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0442\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0440\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0439\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0437\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0436\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0434\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0433\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0431\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0430\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0428\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0427\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0425\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0424\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0423\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0421\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0420\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0418\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0417\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0416\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0414\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0413\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0411\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0410\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0409\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0407\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0406\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0404\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0403\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0402\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0400\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0399\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0398\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0396\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0395\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0394\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0392\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0391\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0390\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0388\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0387\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0386\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0384\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0383\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0382\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0381\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0379\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0378\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0377\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0375\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0374\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0373\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0372\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0370\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0369\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0368\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0367\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0365\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0364\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0363\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0362\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0360\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0359\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0358\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0357\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0356\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0354\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0353\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0352\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0351\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0350\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0348\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0347\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0346\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0345\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0344\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0343\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0341\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0340\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0339\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0338\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0337\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0336\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0335\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0333\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0332\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0331\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0330\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0329\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0328\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0327\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0326\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0325\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0323\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0322\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0321\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0320\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0319\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0318\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0317\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0316\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0315\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0314\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0313\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0312\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0311\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0309\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0308\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0307\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0306\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0305\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0304\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0303\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0302\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0301\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0300\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0299\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0298\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0297\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0296\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0295\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0294\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0293\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0292\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0291\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0290\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0289\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0288\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0287\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0286\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0285\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0284\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0283\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0282\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0281\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0281\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0280\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0279\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0278\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0277\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0276\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0275\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0274\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0273\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0272\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9824e-04 - mse: 9.9824e-04 - mae: 0.0271\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9152e-04 - mse: 9.9152e-04 - mae: 0.0270\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8483e-04 - mse: 9.8483e-04 - mae: 0.0269\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.7819e-04 - mse: 9.7819e-04 - mae: 0.0268\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.7158e-04 - mse: 9.7158e-04 - mae: 0.0268\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6503e-04 - mse: 9.6503e-04 - mae: 0.0267\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.5849e-04 - mse: 9.5849e-04 - mae: 0.0266\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.5203e-04 - mse: 9.5203e-04 - mae: 0.0265\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4563e-04 - mse: 9.4563e-04 - mae: 0.0264\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3922e-04 - mse: 9.3922e-04 - mae: 0.0263\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3290e-04 - mse: 9.3290e-04 - mae: 0.0262\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2660e-04 - mse: 9.2660e-04 - mae: 0.0261\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2033e-04 - mse: 9.2033e-04 - mae: 0.0260\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1412e-04 - mse: 9.1412e-04 - mae: 0.0260\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0795e-04 - mse: 9.0795e-04 - mae: 0.0259\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0182e-04 - mse: 9.0182e-04 - mae: 0.0258\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.9573e-04 - mse: 8.9573e-04 - mae: 0.0257\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.8970e-04 - mse: 8.8970e-04 - mae: 0.0256\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8369e-04 - mse: 8.8369e-04 - mae: 0.0255\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.7772e-04 - mse: 8.7772e-04 - mae: 0.0254\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.7179e-04 - mse: 8.7179e-04 - mae: 0.0253\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.6590e-04 - mse: 8.6590e-04 - mae: 0.0253\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6007e-04 - mse: 8.6007e-04 - mae: 0.0252\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5425e-04 - mse: 8.5425e-04 - mae: 0.0251\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.4848e-04 - mse: 8.4848e-04 - mae: 0.0250\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.4277e-04 - mse: 8.4277e-04 - mae: 0.0249\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.3706e-04 - mse: 8.3706e-04 - mae: 0.0248\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3144e-04 - mse: 8.3144e-04 - mae: 0.0247\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2581e-04 - mse: 8.2581e-04 - mae: 0.0247\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2023e-04 - mse: 8.2023e-04 - mae: 0.0246\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.1470e-04 - mse: 8.1470e-04 - mae: 0.0245\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0919e-04 - mse: 8.0919e-04 - mae: 0.0244\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0373e-04 - mse: 8.0373e-04 - mae: 0.0243\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9829e-04 - mse: 7.9829e-04 - mae: 0.0243\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.9294e-04 - mse: 7.9294e-04 - mae: 0.0242\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.8757e-04 - mse: 7.8757e-04 - mae: 0.0241\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.8225e-04 - mse: 7.8225e-04 - mae: 0.0240\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.7697e-04 - mse: 7.7697e-04 - mae: 0.0239\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7172e-04 - mse: 7.7172e-04 - mae: 0.0238\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6653e-04 - mse: 7.6653e-04 - mae: 0.0238\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.6134e-04 - mse: 7.6134e-04 - mae: 0.0237\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5620e-04 - mse: 7.5620e-04 - mae: 0.0236\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5109e-04 - mse: 7.5109e-04 - mae: 0.0235\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4603e-04 - mse: 7.4603e-04 - mae: 0.0234\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.4099e-04 - mse: 7.4099e-04 - mae: 0.0234\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3598e-04 - mse: 7.3598e-04 - mae: 0.0233\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.3102e-04 - mse: 7.3102e-04 - mae: 0.0232\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2609e-04 - mse: 7.2609e-04 - mae: 0.0231\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.2119e-04 - mse: 7.2119e-04 - mae: 0.0231\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1631e-04 - mse: 7.1631e-04 - mae: 0.0230\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.1148e-04 - mse: 7.1148e-04 - mae: 0.0229\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.0666e-04 - mse: 7.0666e-04 - mae: 0.0228\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0191e-04 - mse: 7.0191e-04 - mae: 0.0227\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9717e-04 - mse: 6.9717e-04 - mae: 0.0227\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9247e-04 - mse: 6.9247e-04 - mae: 0.0226\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8779e-04 - mse: 6.8779e-04 - mae: 0.0225\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8314e-04 - mse: 6.8314e-04 - mae: 0.0224\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7852e-04 - mse: 6.7852e-04 - mae: 0.0224\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7396e-04 - mse: 6.7396e-04 - mae: 0.0223\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6940e-04 - mse: 6.6940e-04 - mae: 0.0222\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6489e-04 - mse: 6.6489e-04 - mae: 0.0221\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6040e-04 - mse: 6.6040e-04 - mae: 0.0221\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5593e-04 - mse: 6.5593e-04 - mae: 0.0220\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5150e-04 - mse: 6.5150e-04 - mae: 0.0219\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4712e-04 - mse: 6.4712e-04 - mae: 0.0218\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.4275e-04 - mse: 6.4275e-04 - mae: 0.0218\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.3841e-04 - mse: 6.3841e-04 - mae: 0.0217\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3409e-04 - mse: 6.3409e-04 - mae: 0.0216\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2982e-04 - mse: 6.2982e-04 - mae: 0.0215\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.2557e-04 - mse: 6.2557e-04 - mae: 0.0215\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.2134e-04 - mse: 6.2134e-04 - mae: 0.0214\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1715e-04 - mse: 6.1715e-04 - mae: 0.0213\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.1299e-04 - mse: 6.1299e-04 - mae: 0.0213\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.0885e-04 - mse: 6.0885e-04 - mae: 0.0212\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0472e-04 - mse: 6.0472e-04 - mae: 0.0211\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0065e-04 - mse: 6.0065e-04 - mae: 0.0210\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.9659e-04 - mse: 5.9659e-04 - mae: 0.0210\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.9258e-04 - mse: 5.9258e-04 - mae: 0.0209\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8857e-04 - mse: 5.8857e-04 - mae: 0.0208\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.8460e-04 - mse: 5.8460e-04 - mae: 0.0208\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.8064e-04 - mse: 5.8064e-04 - mae: 0.0207\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7674e-04 - mse: 5.7674e-04 - mae: 0.0206\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7285e-04 - mse: 5.7285e-04 - mae: 0.0205\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6897e-04 - mse: 5.6897e-04 - mae: 0.0205\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.6513e-04 - mse: 5.6513e-04 - mae: 0.0204\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6132e-04 - mse: 5.6132e-04 - mae: 0.0203\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5753e-04 - mse: 5.5753e-04 - mae: 0.0203\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.5377e-04 - mse: 5.5377e-04 - mae: 0.0202\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5004e-04 - mse: 5.5004e-04 - mae: 0.0201\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4631e-04 - mse: 5.4631e-04 - mae: 0.0201\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4263e-04 - mse: 5.4263e-04 - mae: 0.0200\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3895e-04 - mse: 5.3895e-04 - mae: 0.0199\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3532e-04 - mse: 5.3532e-04 - mae: 0.0199\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3171e-04 - mse: 5.3171e-04 - mae: 0.0198\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2811e-04 - mse: 5.2811e-04 - mae: 0.0197\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2455e-04 - mse: 5.2455e-04 - mae: 0.0197\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.2101e-04 - mse: 5.2101e-04 - mae: 0.0196\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.1748e-04 - mse: 5.1748e-04 - mae: 0.0195\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1400e-04 - mse: 5.1400e-04 - mae: 0.0195\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1053e-04 - mse: 5.1053e-04 - mae: 0.0194\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0709e-04 - mse: 5.0709e-04 - mae: 0.0193\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.0366e-04 - mse: 5.0366e-04 - mae: 0.0193\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.0026e-04 - mse: 5.0026e-04 - mae: 0.0192\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9689e-04 - mse: 4.9689e-04 - mae: 0.0191\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.9354e-04 - mse: 4.9354e-04 - mae: 0.0191\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.9020e-04 - mse: 4.9020e-04 - mae: 0.0190\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8690e-04 - mse: 4.8690e-04 - mae: 0.0189\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.8360e-04 - mse: 4.8360e-04 - mae: 0.0189\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8033e-04 - mse: 4.8033e-04 - mae: 0.0188\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7710e-04 - mse: 4.7710e-04 - mae: 0.0187\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7389e-04 - mse: 4.7389e-04 - mae: 0.0187\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.7067e-04 - mse: 4.7067e-04 - mae: 0.0186\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6750e-04 - mse: 4.6750e-04 - mae: 0.0186\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.6435e-04 - mse: 4.6435e-04 - mae: 0.0185\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.6122e-04 - mse: 4.6122e-04 - mae: 0.0184\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.5810e-04 - mse: 4.5810e-04 - mae: 0.0184\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5500e-04 - mse: 4.5500e-04 - mae: 0.0183\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5193e-04 - mse: 4.5193e-04 - mae: 0.0182\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4888e-04 - mse: 4.4888e-04 - mae: 0.0182\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.4585e-04 - mse: 4.4585e-04 - mae: 0.0181\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.4283e-04 - mse: 4.4283e-04 - mae: 0.0181\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3986e-04 - mse: 4.3986e-04 - mae: 0.0180\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3688e-04 - mse: 4.3688e-04 - mae: 0.0179\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3394e-04 - mse: 4.3394e-04 - mae: 0.0179\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3100e-04 - mse: 4.3100e-04 - mae: 0.0178\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2811e-04 - mse: 4.2811e-04 - mae: 0.0178\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2521e-04 - mse: 4.2521e-04 - mae: 0.0177\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.2233e-04 - mse: 4.2233e-04 - mae: 0.0176\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1949e-04 - mse: 4.1949e-04 - mae: 0.0176\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1666e-04 - mse: 4.1666e-04 - mae: 0.0175\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1384e-04 - mse: 4.1384e-04 - mae: 0.0175\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.1105e-04 - mse: 4.1105e-04 - mae: 0.0174\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0828e-04 - mse: 4.0828e-04 - mae: 0.0173\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0552e-04 - mse: 4.0552e-04 - mae: 0.0173\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0277e-04 - mse: 4.0277e-04 - mae: 0.0172\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0006e-04 - mse: 4.0006e-04 - mae: 0.0172\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9736e-04 - mse: 3.9736e-04 - mae: 0.0171\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9467e-04 - mse: 3.9467e-04 - mae: 0.0171\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.9202e-04 - mse: 3.9202e-04 - mae: 0.0170\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8936e-04 - mse: 3.8936e-04 - mae: 0.0169\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8675e-04 - mse: 3.8675e-04 - mae: 0.0169\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8413e-04 - mse: 3.8413e-04 - mae: 0.0168\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8153e-04 - mse: 3.8153e-04 - mae: 0.0168\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7896e-04 - mse: 3.7896e-04 - mae: 0.0167\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7640e-04 - mse: 3.7640e-04 - mae: 0.0167\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7385e-04 - mse: 3.7385e-04 - mae: 0.0166\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7133e-04 - mse: 3.7133e-04 - mae: 0.0165\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6883e-04 - mse: 3.6883e-04 - mae: 0.0165\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.6634e-04 - mse: 3.6634e-04 - mae: 0.0164\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6388e-04 - mse: 3.6388e-04 - mae: 0.0164\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6142e-04 - mse: 3.6142e-04 - mae: 0.0163\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5896e-04 - mse: 3.5896e-04 - mae: 0.0163\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5655e-04 - mse: 3.5655e-04 - mae: 0.0162\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5413e-04 - mse: 3.5413e-04 - mae: 0.0162\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5176e-04 - mse: 3.5176e-04 - mae: 0.0161\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4937e-04 - mse: 3.4937e-04 - mae: 0.0160\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4702e-04 - mse: 3.4702e-04 - mae: 0.0160\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4467e-04 - mse: 3.4467e-04 - mae: 0.0159\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4236e-04 - mse: 3.4236e-04 - mae: 0.0159\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4003e-04 - mse: 3.4003e-04 - mae: 0.0158\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3775e-04 - mse: 3.3775e-04 - mae: 0.0158\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3545e-04 - mse: 3.3545e-04 - mae: 0.0157\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3319e-04 - mse: 3.3319e-04 - mae: 0.0157\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3094e-04 - mse: 3.3094e-04 - mae: 0.0156\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2872e-04 - mse: 3.2872e-04 - mae: 0.0156\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2649e-04 - mse: 3.2649e-04 - mae: 0.0155\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2430e-04 - mse: 3.2430e-04 - mae: 0.0155\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2211e-04 - mse: 3.2211e-04 - mae: 0.0154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label = 'loss')\n",
        "plt.plot(history.history['mae'],label = 'mae')\n",
        "# epoch 별 훈련 손실 및 평가지표의 시각화 \n",
        "# 앞 부분의 epoch 은 손실이 급격히 감소하는 것을 확인 할수 있다. \n",
        "# "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "0BKNIBIaFwA6",
        "outputId": "f18f51f2-35d0-4475-df91-eaa4753cda9e"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3d95db6610>]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label = 'loss')\n",
        "plt.plot(history.history['mae'],label = 'mae')\n",
        "plt.xlim(-1,20)\n",
        "plt.legend()\n",
        "# 5 epoch까지는 손실이 급격히 감소하다가 감소폭이 둔화되면서 조금씩\n",
        "# 감소되는것을 확인할수 있다. 즉 모델 훈련 초기 단계에는 학습이\n",
        "# 매우 빠른 속도로 진행되다가 일정 epoch 이후에는 학습속도가 느려지는\n",
        "# 패턴이 보인다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "Qc0fh73cGMIG",
        "outputId": "cd9074e4-93b2-4dd2-a5a5-a3fe5addafaf"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3d95d7ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 203
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증...\n",
        "model.evaluate(x,y)\n",
        "# 일반적으로 검증 데이터 셋을 입력하여 검증한다. 여기서는 별도의 검증 데이터셋을 만들지 않아서 훈련용 데이터를 대입하여 결과를 확인한다.\n",
        "# 두개의 지표 loss와 mse를 확인한다.\n",
        "\n",
        "# 사전에 검증 데이터를 준비하여(훈련용과 검증용으로 나눈... ) 성능을 평가하는것이 일반적이다.\n",
        "# 이러한 방법을 교차 검증 cross validataion라고 부른다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKnBbdooGW9P",
        "outputId": "98d0de4a-eb4b-4d37-d18b-1ab655d1a2df"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 332ms/step - loss: 3.1993e-04 - mse: 3.1993e-04 - mae: 0.0154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00031992868753150105, 0.00031992868753150105, 0.01535253506153822]"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "# 훈련이 완료된 모델의 결과에 predict()메소드를 사용하여 새로운 입력 데이터를\n",
        "# 넣어 주면 모델의 예측 값을 얻게 된다.\n",
        "# 모델이 예측 결과로 출력하는 값은 32.0.... 이다.\n",
        "# 데이터 셋 생성 할때 정의한\n",
        "# y = 3x+2\n",
        "# model.predict([10])는 해당 식에서 x에 10을 대입하였을때 y가 몇인지 예측하는것\n",
        "# 계산한것이 아니라 예측한 값이라는 특징!\n",
        "# 결과가 꽤 근사한 값을 예측한것을 확인할수 있다.\n",
        "\n",
        "model.predict([10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk0Vig2YGTzv",
        "outputId": "edb753ab-6341-434e-f57a-e1646b3b93cf"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.074203]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUYiYSThJ9dZ",
        "outputId": "7d70ae75-0d18-4f28-8672-b351a2fffa28"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.016138]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFGyOBOjKT1T",
        "outputId": "6d16059b-9c75-4ed3-859e-691329efef7b"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20.02775]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    }
  ]
}